{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOc3Zcd6vrdrnL5tpzmv66d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalafadli/UAS_AI_2023/blob/main/UAS_Text_Mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PcytDwwiGJ1J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        " data = pd.read_csv('twitter_MBTI.csv')\n",
        " return data"
      ],
      "metadata": {
        "id": "SevM8wfwLek2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_df = load_data()"
      ],
      "metadata": {
        "id": "sKCWxHsMLenf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tampilkan 5 data hasil pengambilan data dar exel\n",
        "tweet_df.head(5)"
      ],
      "metadata": {
        "id": "Qw4X-dyyLerL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mengubah urutan kolom dan dimaasukkan ke data frame agar mudah ke bagian preprosseing\n",
        "df = pd.DataFrame(tweet_df[['label','text']])"
      ],
      "metadata": {
        "id": "X57dk77cMPB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hitung total data\n",
        "df.shape"
      ],
      "metadata": {
        "id": "pgMVSZZMMD_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#menghitung banyaknya data sesuai jenis label nya\n",
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "3rxvl6HAMECg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#memunculkan data grafik berdasarkan label untuk menunjukkan keseimbangan data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "label_cnt = Counter(df.label)\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "\n",
        "plt.bar(label_cnt.keys(), label_cnt.values())\n",
        "\n",
        "plt.title(\"Dataset labels distribuition\")\n",
        "\n",
        "#mengubah huruf menjadi kecil semua\n",
        "df['lower'] = df['text'].str.lower()"
      ],
      "metadata": {
        "id": "NazXiPTHMEGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re # impor modul regular expression\n",
        "\n",
        "def hapus_angka(tweet):\n",
        "  tweet = re.sub(r\"\\d+\", \"\", tweet)\n",
        "  return tweet\n"
      ],
      "metadata": {
        "id": "UrAr-D1FMyqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['h_angka']= df['lower'].apply(lambda x: hapus_angka(x))"
      ],
      "metadata": {
        "id": "LdS2OfX5My3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "twsOuPwBM751"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import stopword\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords_indonesia = stopwords.words('indonesian')"
      ],
      "metadata": {
        "id": "H1RTnEHZM79W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sastrawi"
      ],
      "metadata": {
        "id": "FMSOYNzENbo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import sastrawi\n",
        "\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "factory = StemmerFactory()\n",
        "\n",
        "stemmer = factory.create_stemmer()"
      ],
      "metadata": {
        "id": "Np47D41INbsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize\n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "metadata": {
        "id": "df-Wng8VNkMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#persiapkan untuk emoticon yang di hapus\n",
        "# all\n",
        "\n",
        "emoticons_phone = set(['ðŸ¤£','ðŸ˜','ðŸ˜‚','ðŸ––','ðŸ˜˜','â¤ï¸','ðŸ˜„','ðŸ˜”','â˜ºï¸','ðŸ‘','ðŸ˜Š','ðŸ˜','ðŸ˜­','ðŸ’‹','ðŸ˜’','ðŸ˜³','ðŸ˜œ','ðŸ™ˆ','ðŸ˜¡',\n",
        "\n",
        "'ðŸ˜±','ðŸ˜','ðŸ˜¢','ðŸ˜ƒ','ðŸ˜‰','ðŸ˜','ðŸ˜ž','ðŸ˜…','ðŸ˜š','ðŸ™Š','ðŸ˜Œ','ðŸ˜€','ðŸ˜‹','ðŸ˜†','ðŸ˜•','ðŸ‘Œ','ðŸ˜€','ðŸ˜ƒ',\n",
        "\n",
        "'ðŸ˜„','ðŸ˜','ðŸ˜†','ðŸ˜…','ðŸ˜‚','ðŸ¤£','â˜ºï¸','ðŸ˜Š','ðŸ˜‡','ðŸ™‚','ðŸ™ƒ','ðŸ˜‰','ðŸ˜Œ','ðŸ˜','ðŸ¥°','ðŸ˜˜','ðŸ˜—','ðŸ˜™','ðŸ˜š',\n",
        "\n",
        "'ðŸ˜‹','ðŸ˜›','ðŸ˜','ðŸ˜œ','ðŸ¤ª','ðŸ¤¨','ðŸ§','ðŸ¤“','ðŸ˜Ž','ðŸ¤©','ðŸ¥³','ðŸ˜','ðŸ˜’','ðŸ˜ž','ðŸ˜”','ðŸ˜Ÿ','ðŸ˜•','ðŸ™',\n",
        "\n",
        "'â˜¹ï¸','ðŸ˜£','ðŸ˜–','ðŸ˜«','ðŸ˜©','ðŸ¥º','ðŸ˜¢','ðŸ˜­','ðŸ˜¤','ðŸ˜ ','ðŸ˜¡','ðŸ¤¬','ðŸ¤¯','ðŸ˜³','ðŸ¥µ','ðŸ¥¶','ðŸ˜±','ðŸ˜¨',\n",
        "\n",
        "'ðŸ˜°','ðŸ˜¥','ðŸ˜“','ðŸ¤—','ðŸ¤”','ðŸ¤­ðŸ¤«','ðŸ¤¥ðŸ˜¶','ðŸ˜','ðŸ˜‘','ðŸ˜¬','ðŸ™„','ðŸ˜¯','ðŸ˜¦','ðŸ˜§','ðŸ˜®','ðŸ˜²','ðŸ¥±','ðŸ˜´',\n",
        "\n",
        "'ðŸ¤¤','ðŸ˜ª','ðŸ˜µ','ðŸ¤','ðŸ¥´','ðŸ¤¢','ðŸ¤®','ðŸ¤§','ðŸ˜·','ðŸ¤’','ðŸ¤•','ðŸ¤‘','ðŸ¤ ðŸ˜ˆ','ðŸ‘¿','ðŸ‘¹','ðŸ‘º','ðŸ¤¡','ðŸ’©',\n",
        "\n",
        "'ðŸ‘»','ðŸ’€','â˜ ï¸','ðŸ‘½','ðŸ‘¾','ðŸ¤–','ðŸŽƒ','ðŸ˜º','ðŸ˜¸','ðŸ˜»','ðŸ˜¹','ðŸ˜¼','ðŸ˜½','ðŸ™€','ðŸ˜¿','ðŸ˜¾','ðŸ¤²','ðŸ‘','ðŸ¤',\n",
        "\n",
        "'ðŸ‘Ž','ðŸ¤œ','ðŸ¤›','ðŸ¤ž','âœŒï¸','ðŸ¤Ÿ','ðŸ¤˜','ðŸ‘Œ','ðŸ¤','ðŸ‘ˆ','ðŸ‘‰','ðŸ‘†','ðŸ‘‡','â˜ï¸','âœ‹','ðŸ¤š','ðŸ–','ðŸ––','ðŸ‘‹','ðŸ¤™',\n",
        "\n",
        "'ðŸ’ª','ðŸ¦¾','ðŸ‘‡','ðŸ–•','ðŸ™','ðŸ¦¶','ðŸ¦µ','ðŸ¦¿','ðŸ’„','ðŸ’‹','ðŸ‘„','ðŸ¦·','ðŸ‘…','ðŸ‘ƒ','ðŸ¦»','ðŸ‘£','ðŸ‘','ðŸ‘€','ðŸ§ ',\n",
        "\n",
        "'ðŸ—£ðŸ‘¤','ðŸ‘¥','ðŸ‘¶','ðŸ‘§','ðŸ§’','ðŸ‘¦','ðŸ‘©','ðŸ§‘','ðŸ‘¨','ðŸ‘©â€ðŸ¦±','ðŸ§‘â€ðŸ¦±','ðŸ‘¨â€ðŸ¦±ðŸ‘©â€ðŸ¦°','ðŸ§‘â€ðŸ¦°ðŸ‘¨â€ðŸ¦°','ðŸ‘±â€â™€ï¸','ðŸ‘±','ðŸ‘±â€â™‚ï¸','ðŸ‘©â€ðŸ¦³','ðŸ§‘â€ðŸ¦³',\n",
        "\n",
        "'ðŸ‘¨â€ðŸ¦³','ðŸ‘©â€ðŸ¦²','ðŸ§‘â€ðŸ¦²','ðŸ‘¨â€ðŸ¦²','ðŸ§”','ðŸ‘µ','ðŸ§“','ðŸ‘´','ðŸ‘²','ðŸ‘³â€â™€ï¸','ðŸ‘³','ðŸ‘³â€â™‚ï¸','ðŸ§•','ðŸ‘®â€â™€ï¸','ðŸ‘²','ðŸ‘®â€â™‚ï¸','ðŸ‘·â€â™€ï¸','ðŸ‘·','ðŸ‘·â€â™‚ï¸',\n",
        "\n",
        "'ðŸ’‚â€â™€ï¸','ðŸ’‚','ðŸ’‚â€â™‚ï¸','ðŸ•µï¸â€â™€ï¸','ðŸ•µï¸','ðŸ•µï¸â€â™‚ï¸','ðŸ‘©â€âš•ï¸','ðŸ§‘â€âš•ï¸','ðŸ‘¨â€âš•ï¸','ðŸ‘©â€ðŸŒ¾','ðŸ’','ðŸ™Š','ðŸµ','ðŸ™ˆ','ðŸ™‰','ðŸ·','ðŸ»','ðŸ¶','ðŸ±',\n",
        "\n",
        "'ðŸ¦Š','ðŸš—','ðŸš•','ðŸš™','ðŸšŒ','ðŸšŽ','ðŸŽ','ðŸš›','ðŸšš','ðŸš','ðŸš’','ðŸš‘','ðŸš“','ðŸ¢','ðŸ ','ðŸ¡','ðŸ¬','ðŸ˜','ðŸ£',\n",
        "\n",
        "'ðŸš','ðŸ¤','ðŸ—','ðŸ¥','â›ºï¸','ðŸ¦','ðŸ›','ðŸ’’','ðŸ©','ðŸ«','ðŸª','ðŸ¨','â›ªï¸','ðŸ•Œ','ðŸ•','ðŸ›•','ðŸ•‹','â›©','ðŸ“ˆ',\n",
        "\n",
        "'ðŸ“‰','ðŸ—’','ðŸ—“'])"
      ],
      "metadata": {
        "id": "sDXjfzFMNkP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sad happy\n",
        "\n",
        "emoticons_sad_happy= set(['â—‰â€¿â—‰','o ^ - ^ o','^_^',':)',':^)',\n",
        "\n",
        "': NS)','8)',':HAI','@',':HAI)',':â€‘)',\n",
        "\n",
        "':P',':@','8â€‘D',':â€‘)',':-&','=D',':â€‘p',\n",
        "\n",
        "'=â€‘D','XD',':D',':-))','%-)',':}',\n",
        "\n",
        "':c)',':^)',':C','>:3',':>','L',':-/','>:/',\n",
        "\n",
        "':S','>:[','@',':-(','\"[\"',':-<',\n",
        "\n",
        "'=\\\\','=/','>:(',':',':{','>:\\\\',\n",
        "\n",
        "'(',':','(\", \")',':','(\"',':-c',\n",
        "\n",
        "'> :(',':â€‘',':NS('])\n",
        "\n",
        "# all emot happy + sad\n",
        "\n",
        "emoticons = emoticons_phone.union(emoticons_sad_happy)"
      ],
      "metadata": {
        "id": "QUXOoetPNvmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fulltext(tweet):\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    #remove coma\n",
        "    tweet = re.sub(r',','',tweet)\n",
        "    #remove angka\n",
        "    tweet = re.sub('[0-9]+', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False,\n",
        "    strip_handles=True, reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_indonesia and # remove stopwords\n",
        "            word not in emoticons and # remove emoticons\n",
        "            word not in string.punctuation): # remove punctuation\n",
        "    #tweets_clean.append(word)\n",
        "            stem_word = stemmer.stem(word) # stemming word\n",
        "            tweets_clean.append(stem_word)\n",
        "            return tweets_clean"
      ],
      "metadata": {
        "id": "AeFB_APvNwtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['token'] = df['h_angka'].apply(lambda x: fulltext(x))"
      ],
      "metadata": {
        "id": "G2uNVO576s-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "sIyBJvCw7HvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove punct\n",
        "def remove_punct(text):\n",
        "    text = \" \".join([char for char in text if char not in string.punctuation])\n",
        "    return text"
      ],
      "metadata": {
        "id": "TX9C39hxlorL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#simpan di kolom tabel baru tweet\n",
        "df['fulltext'] = df['text'].apply(lambda x: remove_punct(x))"
      ],
      "metadata": {
        "id": "C8k8yAFroZb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "4THa0I2foZfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mengurutkan ascending urutkan kolom tweet\n",
        "df.sort_values(\"fulltext\", inplace = True)"
      ],
      "metadata": {
        "id": "ETI8pOE_ot92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "0kqwuvnUouBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "B-reVs8vo0ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_transformer = CountVectorizer().fit(df['fulltext'])\n",
        "bow_transformer.vocabulary_"
      ],
      "metadata": {
        "id": "Qo-9u16Io0ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = bow_transformer.get_feature_names_out()\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "E4QWTE-vtWKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_bow = bow_transformer.transform(df['text'])\n",
        "print(text_bow)\n",
        "if teks is not None:\n",
        "    teks_kecil = teks.lower()\n",
        "else:\n",
        "    print(\"Variabel 'teks' tidak memiliki nilai.\")\n"
      ],
      "metadata": {
        "id": "Qf32MNFNpNos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = text_bow.toarray()\n",
        "print(X)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "SwWyfax-pNss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer=TfidfTransformer().fit(text_bow)\n",
        "print(tfidf_transformer)\n",
        "\n",
        "tweet_tfidf=tfidf_transformer.transform(text_bow)\n",
        "print(tweet_tfidf)\n",
        "print(tweet_tfidf.shape)"
      ],
      "metadata": {
        "id": "OC0GO6sMumUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, df.label,test_size=0.2, random_state=35)"
      ],
      "metadata": {
        "id": "9FeyL1ag3c7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB().fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "_y75zImR3dLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(x_test)\n",
        "predict= pd.Series(prediction)\n",
        "print(predict.to_string())"
      ],
      "metadata": {
        "id": "eqaefugk33YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_label= pd.Series(y_test)\n",
        "print(true_label.to_string())"
      ],
      "metadata": {
        "id": "7Bdl69rs33pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from pandas import DataFrame\n",
        "\n",
        "\n",
        "t = time()\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "test_time = time() - t\n",
        "print(\"test time:  %0.3fs\" % test_time)\n",
        "\n",
        "score1 = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"accuracy:   %0.3f\" % score1)\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred, target_names=['negatif', 'netral', 'positif']))\n",
        "\n",
        "columns = ['negatif','netral','positif']\n",
        "confm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = DataFrame(confm, index=columns, columns=columns)\n",
        "\n",
        "ax = sn.heatmap(df_cm, cmap='Greens', annot=True)\n",
        "ax.set_title('Confusion matrix')\n",
        "ax.set_xlabel('Label prediksi')"
      ],
      "metadata": {
        "id": "ak4Op-T04IRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model, x_train,y_train, cv=10)\n",
        "\n",
        "# Print the accuracy of each fold:\n",
        "print(scores)\n",
        "\n",
        "# Print the mean accuracy of all 10 folds\n",
        "print(scores.mean())"
      ],
      "metadata": {
        "id": "Equ0vEXq4QwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_data = [\"alhamdulillah vaksin apapun itu aman dan baik bagi tubuh kita\",\n",
        "             \"vaksin hanyalah bisnis pemerintah dan konspirasi elit global\",\n",
        "             \"besok saya dan ibu vaksin di jakarta selatan\"]\n",
        "print(user_data)"
      ],
      "metadata": {
        "id": "G9Ys-VpJ4Q3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_1_unseen =  bow_transformer.transform(user_data)\n",
        "data=test_1_unseen.toarray()\n",
        "print(\"diubah menjadi array: \\n \",data)"
      ],
      "metadata": {
        "id": "UOA1LB7JU0nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ukuran dari array: \\n \",data.shape)"
      ],
      "metadata": {
        "id": "B5rUg9gCU0q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_unseen = model.predict(data)\n",
        "print(prediction_unseen)"
      ],
      "metadata": {
        "id": "etpXLUTVU5Ce"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}